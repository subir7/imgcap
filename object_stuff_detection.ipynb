{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rzmBiNk19KO"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/MSCOCO/Flicker8k_Dataset.zip\" -d \"/content\"\n",
        "!unzip \"/content/drive/MyDrive/MSCOCO/Flickr8k_text.zip\" -d \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "COMPLETE MSCOCO OBJECT + STUFF FEATURE EXTRACTOR\n",
        "\n",
        "Extracts BOTH:\n",
        "1. MSCOCO Objects (80 classes): person, car, dog, etc. - via Object Detection\n",
        "2. MSCOCO Stuff (91 classes): sky, grass, water, etc. - via Semantic Segmentation\n",
        "\n",
        "Total: 171 MSCOCO classes\n",
        "\n",
        "Feature Output: 180D\n",
        "- 80D: Object class counts\n",
        "- 91D: Stuff class presence/coverage\n",
        "- 9D: Scene statistics (objects + stuff combined)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from typing import List, Dict, Tuple\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================================\n",
        "# MSCOCO CLASS DEFINITIONS\n",
        "# ============================================================================\n",
        "\n",
        "# 80 MSCOCO Object Classes\n",
        "MSCOCO_OBJECTS = [\n",
        "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
        "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
        "    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
        "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
        "    'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',\n",
        "    'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
        "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "# 91 MSCOCO Stuff Classes (background/scene elements)\n",
        "MSCOCO_STUFF_SIMPLIFIED = [\n",
        "    # Nature/Outdoor\n",
        "    'sky', 'grass', 'tree', 'mountain', 'hill', 'rock', 'water', 'sea', 'river', 'lake',\n",
        "    'sand', 'snow', 'fog', 'clouds', 'bush', 'flower', 'leaves', 'branch', 'dirt', 'mud',\n",
        "\n",
        "    # Buildings/Structure\n",
        "    'building', 'house', 'bridge', 'fence', 'wall', 'roof', 'door', 'window', 'stairs',\n",
        "    'ceiling', 'floor', 'platform', 'pavement', 'road', 'railroad', 'ground',\n",
        "\n",
        "    # Indoor\n",
        "    'cabinet', 'shelf', 'table', 'counter', 'carpet', 'rug', 'curtain', 'blanket',\n",
        "    'pillow', 'towel', 'mirror', 'light', 'paper', 'cardboard', 'wood', 'metal',\n",
        "    'plastic', 'glass', 'tile', 'brick', 'stone',\n",
        "\n",
        "    # Other\n",
        "    'banner', 'net', 'tent', 'playingfield', 'fruit', 'vegetable', 'food', 'cloth',\n",
        "    'textile', 'plant', 'gravel', 'moss', 'straw'\n",
        "]\n",
        "\n",
        "MSCOCO_STUFF = MSCOCO_STUFF_SIMPLIFIED[:91]  # Ensure exactly 91 classes\n",
        "\n",
        "print(f\"Loaded {len(MSCOCO_OBJECTS)} object classes\")\n",
        "print(f\"Loaded {len(MSCOCO_STUFF)} stuff classes\")\n",
        "\n",
        "# ============================================================================\n",
        "# OBJECT DETECTOR\n",
        "# ============================================================================\n",
        "\n",
        "class ObjectDetector:\n",
        "    \"\"\"Detects MSCOCO Objects (80 classes)\"\"\"\n",
        "\n",
        "    def __init__(self, confidence_threshold=0.3, max_objects=20):\n",
        "        self.confidence_threshold = confidence_threshold\n",
        "        self.max_objects = max_objects\n",
        "        self.object_classes = MSCOCO_OBJECTS\n",
        "\n",
        "        print(\"Loading SSD MobileNet V2 for object detection...\")\n",
        "        try:\n",
        "            self.model = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
        "            print(\"✓ Object detector loaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Failed to load object detector: {e}\")\n",
        "            self.model = None\n",
        "\n",
        "    def detect(self, image_path):\n",
        "        \"\"\"Detect objects and return class counts\"\"\"\n",
        "        if self.model is None:\n",
        "            return np.zeros(len(self.object_classes), dtype=np.float32)\n",
        "\n",
        "        # Load image\n",
        "        if isinstance(image_path, str):\n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            image = image_path\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "\n",
        "        # Run detection\n",
        "        input_tensor = tf.convert_to_tensor(image)[tf.newaxis, ...]\n",
        "        detections = self.model(input_tensor)\n",
        "\n",
        "        boxes = detections['detection_boxes'][0].numpy()\n",
        "        classes = detections['detection_classes'][0].numpy().astype(int)\n",
        "        scores = detections['detection_scores'][0].numpy()\n",
        "\n",
        "        # Count objects by class\n",
        "        class_counts = np.zeros(len(self.object_classes), dtype=np.float32)\n",
        "\n",
        "        valid_indices = np.where(scores >= self.confidence_threshold)[0][:self.max_objects]\n",
        "\n",
        "        for idx in valid_indices:\n",
        "            class_id = classes[idx] - 1  # COCO is 1-indexed\n",
        "            if 0 <= class_id < len(self.object_classes):\n",
        "                class_counts[class_id] += 1\n",
        "\n",
        "        # Normalize by max count\n",
        "        max_count = max(class_counts.max(), 1.0)\n",
        "        class_counts = class_counts / max_count\n",
        "\n",
        "        return class_counts\n",
        "\n",
        "# ============================================================================\n",
        "# STUFF DETECTOR (Semantic Segmentation)\n",
        "# ============================================================================\n",
        "\n",
        "class StuffDetector:\n",
        "\n",
        "\n",
        "    def __init__(self, coverage_threshold=0.01):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            coverage_threshold: Minimum % of image covered to count as present\n",
        "        \"\"\"\n",
        "        self.coverage_threshold = coverage_threshold\n",
        "        self.stuff_classes = MSCOCO_STUFF\n",
        "\n",
        "        print(\"Loading DeepLabV3 for stuff/scene detection...\")\n",
        "        try:\n",
        "            # DeepLabV3 with MobileNet V2 backbone\n",
        "            self.model = hub.load(\"https://tfhub.dev/tensorflow/deeplabv3/1\")\n",
        "            print(\"✓ Stuff detector loaded\")\n",
        "            self.model_loaded = True\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not load DeepLabV3: {e}\")\n",
        "            print(\"  Will use color-based heuristics instead\")\n",
        "            self.model_loaded = False\n",
        "\n",
        "    def detect_with_deeplabv3(self, image_path):\n",
        "        \"\"\"Detect stuff using DeepLabV3 semantic segmentation\"\"\"\n",
        "        if not self.model_loaded:\n",
        "            return self.detect_with_heuristics(image_path)\n",
        "\n",
        "        # Load and preprocess image\n",
        "        if isinstance(image_path, str):\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "        else:\n",
        "            image = Image.fromarray(cv2.cvtColor(image_path, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # Resize for model\n",
        "        resized = image.resize((513, 513))\n",
        "        img_array = np.array(resized)\n",
        "\n",
        "        # Run segmentation\n",
        "        input_tensor = tf.convert_to_tensor(img_array)\n",
        "        input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "        output = self.model(input_tensor)\n",
        "        seg_map = output['segmentation_map'][0].numpy()\n",
        "\n",
        "        # Map DeepLabV3 classes to our stuff categories\n",
        "        stuff_presence = self._map_segmentation_to_stuff(seg_map, image.size)\n",
        "\n",
        "        return stuff_presence\n",
        "\n",
        "    def detect_with_heuristics(self, image_path):\n",
        "        \"\"\"\n",
        "        Fallback: Detect stuff using color/texture heuristics\n",
        "        When DeepLabV3 not available\n",
        "        \"\"\"\n",
        "        if isinstance(image_path, str):\n",
        "            image = cv2.imread(image_path)\n",
        "        else:\n",
        "            image = image_path\n",
        "\n",
        "        h, w = image.shape[:2]\n",
        "        total_pixels = h * w\n",
        "\n",
        "        # Convert to different color spaces\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        stuff_features = np.zeros(91, dtype=np.float32)\n",
        "\n",
        "        # Sky detection (top region, blue color)\n",
        "        top_region = image[:h//4, :]\n",
        "        blue_ratio = self._detect_color(top_region, color='blue')\n",
        "        stuff_features[0] = min(blue_ratio * 2, 1.0)  # sky\n",
        "\n",
        "        # Grass detection (bottom region, green color)\n",
        "        bottom_region = image[h*3//4:, :]\n",
        "        green_ratio = self._detect_color(bottom_region, color='green')\n",
        "        stuff_features[1] = min(green_ratio * 2, 1.0)  # grass\n",
        "\n",
        "        # Water detection (blue, not in top region)\n",
        "        middle_region = image[h//4:h*3//4, :]\n",
        "        water_ratio = self._detect_color(middle_region, color='blue')\n",
        "        stuff_features[6] = min(water_ratio * 1.5, 1.0)  # water\n",
        "\n",
        "        # Tree detection (green, with texture)\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        edge_density = np.sum(edges > 0) / total_pixels\n",
        "        green_all = self._detect_color(image, color='green')\n",
        "        stuff_features[2] = min(green_all * edge_density * 5, 1.0)  # tree\n",
        "\n",
        "        # Building detection (gray, rectangular structures)\n",
        "        gray_ratio = self._detect_color(image, color='gray')\n",
        "        stuff_features[20] = min(gray_ratio * 1.5, 1.0)  # building\n",
        "\n",
        "        # Road/pavement (gray, bottom half)\n",
        "        road_ratio = self._detect_color(bottom_region, color='gray')\n",
        "        stuff_features[33] = min(road_ratio * 1.5, 1.0)  # road\n",
        "\n",
        "        # Wall (gray/brown, middle region)\n",
        "        wall_ratio = self._detect_color(middle_region, color='gray')\n",
        "        stuff_features[24] = min(wall_ratio * 1.2, 1.0)  # wall\n",
        "\n",
        "        # Ground (brown/tan)\n",
        "        brown_ratio = self._detect_color(bottom_region, color='brown')\n",
        "        stuff_features[35] = min(brown_ratio * 1.5, 1.0)  # ground\n",
        "\n",
        "        # Sand (light brown/yellow)\n",
        "        sand_ratio = self._detect_color(bottom_region, color='yellow')\n",
        "        stuff_features[10] = min(sand_ratio * 1.2, 1.0)  # sand\n",
        "\n",
        "        # Snow (white, high brightness)\n",
        "        white_ratio = self._detect_color(image, color='white')\n",
        "        stuff_features[11] = min(white_ratio * 1.5, 1.0)  # snow\n",
        "\n",
        "        return stuff_features\n",
        "\n",
        "    def _detect_color(self, region, color='blue'):\n",
        "        \"\"\"Detect color presence in image region\"\"\"\n",
        "        hsv = cv2.cvtColor(region, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        if color == 'blue':\n",
        "            # Blue hue range\n",
        "            lower = np.array([100, 50, 50])\n",
        "            upper = np.array([130, 255, 255])\n",
        "        elif color == 'green':\n",
        "            lower = np.array([35, 40, 40])\n",
        "            upper = np.array([85, 255, 255])\n",
        "        elif color == 'gray':\n",
        "            # Low saturation\n",
        "            lower = np.array([0, 0, 50])\n",
        "            upper = np.array([180, 50, 200])\n",
        "        elif color == 'brown':\n",
        "            lower = np.array([10, 50, 20])\n",
        "            upper = np.array([30, 255, 200])\n",
        "        elif color == 'yellow':\n",
        "            lower = np.array([20, 100, 100])\n",
        "            upper = np.array([35, 255, 255])\n",
        "        elif color == 'white':\n",
        "            lower = np.array([0, 0, 200])\n",
        "            upper = np.array([180, 50, 255])\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "        mask = cv2.inRange(hsv, lower, upper)\n",
        "        ratio = np.sum(mask > 0) / (region.shape[0] * region.shape[1])\n",
        "\n",
        "        return ratio\n",
        "\n",
        "    def _map_segmentation_to_stuff(self, seg_map, image_size):\n",
        "        \"\"\"Map DeepLabV3 classes to MSCOCO stuff classes\"\"\"\n",
        "        # DeepLabV3 uses Pascal VOC classes, simplified mapping\n",
        "        total_pixels = seg_map.size\n",
        "\n",
        "        stuff_presence = np.zeros(91, dtype=np.float32)\n",
        "\n",
        "        # Count pixel coverage for each class\n",
        "        unique, counts = np.unique(seg_map, return_counts=True)\n",
        "\n",
        "        for class_id, count in zip(unique, counts):\n",
        "            coverage = count / total_pixels\n",
        "\n",
        "            # Map DeepLabV3 classes to stuff\n",
        "            # 0=background, 1=aeroplane, 2=bicycle, ..., 15=person, etc.\n",
        "            # Simplified mapping\n",
        "            if class_id == 0:  # background\n",
        "                stuff_presence[0] = max(stuff_presence[0], coverage)  # sky\n",
        "\n",
        "            # Add more mappings as needed\n",
        "\n",
        "        return stuff_presence\n",
        "\n",
        "    def detect(self, image_path):\n",
        "        \"\"\"Main detection method\"\"\"\n",
        "        if self.model_loaded:\n",
        "            try:\n",
        "                return self.detect_with_deeplabv3(image_path)\n",
        "            except:\n",
        "                return self.detect_with_heuristics(image_path)\n",
        "        else:\n",
        "            return self.detect_with_heuristics(image_path)\n",
        "\n",
        "# ============================================================================\n",
        "# COMBINED FEATURE EXTRACTOR\n",
        "# ============================================================================\n",
        "\n",
        "class CompleteFeatureExtractor:\n",
        "    \"\"\"\n",
        "    Extracts BOTH object and stuff features\n",
        "\n",
        "    Output: 180D feature vector\n",
        "    - 80D: Object class counts (normalized)\n",
        "    - 91D: Stuff class presence (coverage %)\n",
        "    - 9D: Combined scene statistics\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.object_detector = ObjectDetector(confidence_threshold=0.3, max_objects=20)\n",
        "        self.stuff_detector = StuffDetector(coverage_threshold=0.01)\n",
        "\n",
        "    def extract_features(self, image_path):\n",
        "        \"\"\"\n",
        "        Extract complete feature vector\n",
        "\n",
        "        Returns:\n",
        "            180D numpy array\n",
        "        \"\"\"\n",
        "        # Detect objects (80D)\n",
        "        object_features = self.object_detector.detect(image_path)\n",
        "\n",
        "        # Detect stuff (91D)\n",
        "        stuff_features = self.stuff_detector.detect(image_path)\n",
        "\n",
        "        # Compute scene statistics (9D)\n",
        "        scene_stats = self._compute_scene_statistics(object_features, stuff_features)\n",
        "\n",
        "        # Combine all features\n",
        "        complete_features = np.concatenate([\n",
        "            object_features,  # 80D\n",
        "            stuff_features,   # 91D\n",
        "            scene_stats       # 9D\n",
        "        ])\n",
        "\n",
        "        return complete_features.astype(np.float32)\n",
        "\n",
        "    def _compute_scene_statistics(self, object_features, stuff_features):\n",
        "        \"\"\"Compute aggregate statistics about the scene\"\"\"\n",
        "        stats = [\n",
        "            np.sum(object_features > 0),           # Number of object types present\n",
        "            np.sum(stuff_features > 0),            # Number of stuff types present\n",
        "            np.mean(object_features),              # Average object presence\n",
        "            np.std(object_features),               # Object diversity\n",
        "            np.mean(stuff_features),               # Average stuff coverage\n",
        "            np.std(stuff_features),                # Stuff diversity\n",
        "            np.max(object_features),               # Max object count\n",
        "            np.max(stuff_features),                # Max stuff coverage\n",
        "            (np.sum(object_features > 0) + np.sum(stuff_features > 0)) / 171  # Overall scene complexity\n",
        "        ]\n",
        "\n",
        "        return np.array(stats, dtype=np.float32)\n",
        "\n",
        "    def get_feature_summary(self, image_path):\n",
        "        \"\"\"Get human-readable summary of detected features\"\"\"\n",
        "        object_features = self.object_detector.detect(image_path)\n",
        "        stuff_features = self.stuff_detector.detect(image_path)\n",
        "\n",
        "        detected_objects = [\n",
        "            MSCOCO_OBJECTS[i] for i in range(len(object_features))\n",
        "            if object_features[i] > 0.1\n",
        "        ]\n",
        "\n",
        "        detected_stuff = [\n",
        "            MSCOCO_STUFF[i] for i in range(len(stuff_features))\n",
        "            if stuff_features[i] > 0.1\n",
        "        ]\n",
        "\n",
        "        return {\n",
        "            'objects': detected_objects,\n",
        "            'stuff': detected_stuff,\n",
        "            'num_objects': len(detected_objects),\n",
        "            'num_stuff': len(detected_stuff)\n",
        "        }\n",
        "\n",
        "# ============================================================================\n",
        "# BATCH PROCESSING FOR FLICKR8K\n",
        "# ============================================================================\n",
        "\n",
        "def process_flickr8k_complete(image_dir, output_csv):\n",
        "    \"\"\"\n",
        "    Process entire Flickr8k dataset with BOTH objects and stuff\n",
        "\n",
        "    Args:\n",
        "        image_dir: Directory containing images\n",
        "        output_csv: Output CSV file path\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"PROCESSING FLICKR8K: OBJECTS + STUFF DETECTION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Initialize extractor\n",
        "    extractor = CompleteFeatureExtractor()\n",
        "\n",
        "    # Get all images\n",
        "    image_files = [f for f in os.listdir(image_dir)\n",
        "                   if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    print(f\"\\nFound {len(image_files)} images\")\n",
        "\n",
        "    # Process images\n",
        "    results = []\n",
        "\n",
        "    for img_file in tqdm(image_files, desc=\"Extracting features\"):\n",
        "        img_path = os.path.join(image_dir, img_file)\n",
        "\n",
        "        try:\n",
        "            features = extractor.extract_features(img_path)\n",
        "            row = [img_file] + features.tolist()\n",
        "            results.append(row)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError processing {img_file}: {e}\")\n",
        "            row = [img_file] + [0.0] * 180\n",
        "            results.append(row)\n",
        "\n",
        "    # Save to CSV\n",
        "    columns = ['filename'] + [f'feat_{i}' for i in range(180)]\n",
        "    df = pd.DataFrame(results, columns=columns)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md5mYphN1_EJ",
        "outputId": "6006969b-4bfd-4b1b-b4db-ccd72a5ab266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 80 object classes\n",
            "Loaded 70 stuff classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    process_flickr8k_complete(\"/content/Flicker8k_Dataset\", \"/content/mscoco_object_stuff_detection.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihz9bXEB2d5T",
        "outputId": "e2e72042-949c-46f7-9023-3823fc642d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PROCESSING FLICKR8K: OBJECTS + STUFF DETECTION\n",
            "================================================================================\n",
            "Loading SSD MobileNet V2 for object detection...\n",
            "✓ Object detector loaded\n",
            "Loading DeepLabV3 for stuff/scene detection...\n",
            "⚠️ Could not load DeepLabV3: https://tfhub.dev/tensorflow/deeplabv3/1 does not appear to be a valid module.\n",
            "  Will use color-based heuristics instead\n",
            "\n",
            "Found 8091 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 8091/8091 [17:12<00:00,  7.84it/s]\n"
          ]
        }
      ]
    }
  ]
}